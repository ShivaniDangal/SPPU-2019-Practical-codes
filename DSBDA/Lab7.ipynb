{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0200930",
   "metadata": {},
   "source": [
    "##### Problem statement: Text Analytics\n",
    "\n",
    "1. Extract Sample document and apply following document preprocessing methods:\n",
    "Tokenization, POS Tagging, stop words removal, Stemming and Lemmatization.\n",
    "2. Create representation of document by calculating Term Frequency and Inverse Document\n",
    "Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e083ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: - \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/osx-64::sphinx==5.0.2=py310hecd8cb5_0\n",
      "  - defaults/osx-64::holoviews==1.15.4=py310hecd8cb5_0\n",
      "  - defaults/osx-64::jupyter==1.0.0=py310hecd8cb5_8\n",
      "  - defaults/osx-64::spyder==5.4.1=py310hecd8cb5_0\n",
      "  - defaults/osx-64::notebook==6.5.2=py310hecd8cb5_0\n",
      "  - defaults/osx-64::transformers==4.24.0=py310hecd8cb5_0\n",
      "  - defaults/osx-64::ipython==8.10.0=py310hecd8cb5_0\n",
      "  - defaults/osx-64::numpydoc==1.5.0=py310hecd8cb5_0\n",
      "  - defaults/osx-64::spyder-kernels==2.4.1=py310hecd8cb5_0\n",
      "  - defaults/osx-64::nbclassic==0.5.2=py310hecd8cb5_0\n",
      "  - defaults/osx-64::qtconsole==5.4.0=py310hecd8cb5_0\n",
      "  - defaults/noarch::jupyterlab_pygments==0.1.2=py_0\n",
      "  - defaults/osx-64::widgetsnbextension==3.5.2=py310hecd8cb5_0\n",
      "  - defaults/osx-64::jupyterlab_server==2.19.0=py310hecd8cb5_0\n",
      "  - defaults/osx-64::hvplot==0.8.2=py310hecd8cb5_0\n",
      "  - defaults/osx-64::notebook-shim==0.2.2=py310hecd8cb5_0\n",
      "  - defaults/noarch::ipywidgets==7.6.5=pyhd3eb1b0_1\n",
      "  - defaults/osx-64::jupyter_server==1.23.4=py310hecd8cb5_0\n",
      "  - defaults/osx-64::jupyter_console==6.6.2=py310hecd8cb5_0\n",
      "  - defaults/osx-64::jupyterlab==3.5.3=py310hecd8cb5_0\n",
      "  - defaults/osx-64::ipykernel==6.19.2=py310h20db666_0\n",
      "  - defaults/osx-64::nbconvert==6.5.4=py310hecd8cb5_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 24.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.5.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/shivanidangal/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - nltk\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.08.22 |       hecd8cb5_0         131 KB  anaconda\n",
      "    certifi-2023.11.17         |  py310hecd8cb5_0         161 KB  anaconda\n",
      "    huggingface_hub-0.17.3     |  py310hecd8cb5_0         412 KB  anaconda\n",
      "    nltk-3.8.1                 |  py310hecd8cb5_0         2.2 MB  anaconda\n",
      "    openssl-1.1.1w             |       hca72f7f_0         3.5 MB  anaconda\n",
      "    pygments-2.15.1            |  py310hecd8cb5_1         1.8 MB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         8.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  huggingface_hub    anaconda/osx-64::huggingface_hub-0.17.3-py310hecd8cb5_0 \n",
      "  pygments           anaconda/osx-64::pygments-2.15.1-py310hecd8cb5_1 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2022.4.26-hecd8cb5_0 --> 2023.08.22-hecd8cb5_0 \n",
      "  certifi                         2022.6.15-py310hecd8cb5_0 --> 2023.11.17-py310hecd8cb5_0 \n",
      "  nltk               anaconda/noarch::nltk-3.7-pyhd3eb1b0_0 --> anaconda/osx-64::nltk-3.8.1-py310hecd8cb5_0 \n",
      "  openssl              pkgs/main::openssl-1.1.1t-hca72f7f_0 --> anaconda::openssl-1.1.1w-hca72f7f_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pygments-2.15.1      | 1.8 MB    |                                       |   0% \n",
      "huggingface_hub-0.17 | 412 KB    |                                       |   0% \u001b[A\n",
      "\n",
      "certifi-2023.11.17   | 161 KB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 131 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 3.5 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nltk-3.8.1           | 2.2 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "huggingface_hub-0.17 | 412 KB    | #4                                    |   4% \u001b[A\n",
      "huggingface_hub-0.17 | 412 KB    | ##############3                       |  39% \u001b[A\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 131 KB    | ####5                                 |  12% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 131 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "huggingface_hub-0.17 | 412 KB    | ####################1                 |  54% \u001b[A\n",
      "huggingface_hub-0.17 | 412 KB    | ##################################### | 100% \u001b[A\n",
      "huggingface_hub-0.17 | 412 KB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nltk-3.8.1           | 2.2 MB    | 2                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nltk-3.8.1           | 2.2 MB    | ###1                                  |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nltk-3.8.1           | 2.2 MB    | ######2                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nltk-3.8.1           | 2.2 MB    | ###########9                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 3.5 MB    | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nltk-3.8.1           | 2.2 MB    | ##################3                   |  50% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 3.5 MB    | #####9                                |  16% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nltk-3.8.1           | 2.2 MB    | ##########################1           |  71% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 3.5 MB    | ###########4                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nltk-3.8.1           | 2.2 MB    | ####################################2 |  98% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 3.5 MB    | ###############8                      |  43% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 3.5 MB    | #######################8              |  64% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 3.5 MB    | ################################9     |  89% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nltk-3.8.1           | 2.2 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 3.5 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "certifi-2023.11.17   | 161 KB    | ###6                                  |  10% \u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c anaconda nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "458d2a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shivanidangal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22fcee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize#for tokenization\n",
    "from nltk.corpus import stopwords#for stopwords removal\n",
    "from nltk.stem import SnowballStemmer#for stemming\n",
    "from nltk.stem import WordNetLemmatizer#for lemmatization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer#for TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b2fde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (3.32.0)\n",
      "Requirement already satisfied: requests in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (4.4.0)\n",
      "Requirement already satisfied: pillow in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: pydub in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (0.22.0)\n",
      "Requirement already satisfied: python-multipart in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: altair>=4.2.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (5.0.1)\n",
      "Requirement already satisfied: pygments>=2.12.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (2.15.1)\n",
      "Requirement already satisfied: aiofiles in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (23.1.0)\n",
      "Requirement already satisfied: markupsafe in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (0.17.3)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: semantic-version in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: orjson in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (3.8.14)\n",
      "Requirement already satisfied: pyyaml in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: aiohttp in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (3.8.4)\n",
      "Requirement already satisfied: numpy in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (1.23.5)\n",
      "Requirement already satisfied: ffmpy in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: fastapi in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (0.95.2)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (0.3.3)\n",
      "Requirement already satisfied: pandas in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: jinja2 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: pydantic in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (1.10.8)\n",
      "Requirement already satisfied: matplotlib in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (3.7.0)\n",
      "Requirement already satisfied: websockets>=10.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (10.4)\n",
      "Requirement already satisfied: gradio-client>=0.2.4 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (0.2.5)\n",
      "Requirement already satisfied: httpx in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (0.24.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from altair>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: packaging in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio-client>=0.2.4->gradio) (22.0)\n",
      "Requirement already satisfied: fsspec in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio-client>=0.2.4->gradio) (2022.11.0)\n",
      "Requirement already satisfied: filelock in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.13.0->gradio) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.13.0->gradio) (4.64.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from pandas->gradio) (2022.7)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (7.1.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from aiohttp->gradio) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from aiohttp->gradio) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from aiohttp->gradio) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from aiohttp->gradio) (1.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from aiohttp->gradio) (2.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from aiohttp->gradio) (1.3.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from httpx->gradio) (0.17.2)\n",
      "Requirement already satisfied: certifi in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from httpx->gradio) (2024.2.2)\n",
      "Requirement already satisfied: idna in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from httpx->gradio) (3.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from matplotlib->gradio) (4.25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from matplotlib->gradio) (1.0.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from requests->gradio) (1.26.14)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.5.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: uc-micro-py in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e9080ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425e9736",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "035a7262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenization(input):\n",
    "    token= word_tokenize(input)\n",
    "    return token\n",
    "\n",
    "def sent_tokenization(input):\n",
    "    token= sent_tokenize(input)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7969c12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.32.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#INTERFACE FOR WORD TOKENIZATION\n",
    "#Input: Hi, my name is Shivani.\n",
    "#Output: ['Hi', ',', 'my', 'name', 'is', 'Shivani', '.']\n",
    "\n",
    "demo1= gr.Interface(fn=word_tokenization, inputs=\"text\", outputs=\"text\")\n",
    "demo1.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a35ff6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#INTERFACE FOR BOTH WORD AND SENTENCE TOKENIZATION\n",
    "\n",
    "demo= gr.Blocks()\n",
    "with demo:\n",
    "    gr.Markdown(\"# Tokenization\")\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"Word Tokenization\"):\n",
    "            with gr.Row():\n",
    "                word_ip= gr.Textbox(label=\"Input Data\")\n",
    "                word_op= gr.Textbox(label=\"Output Tokens\")\n",
    "            word_button= gr.Button(\"Generate Tokens\")\n",
    "        with gr.TabItem(\"Sentence= Tokenization\"):\n",
    "            with gr.Row():\n",
    "                sent_ip= gr.Textbox(label=\"Input Data\")\n",
    "                sent_op= gr.Textbox(label=\"Output Tokens\")\n",
    "            sent_button= gr.Button(\"Generate Tokens\")\n",
    "    word_button.click(word_tokenization, inputs=word_ip, outputs=word_op)\n",
    "    sent_button.click(sent_tokenization, inputs=sent_ip, outputs=sent_op)\n",
    "    \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c93ad7",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33990e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball_stemmer= SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6204e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= \"Hello I am Shivani. I am a Engineering student.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13f7a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens= nltk.word_tokenize(text)\n",
    "stemmed_word= [snowball_stemmer.stem(word) for word in word_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0c7521c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'i', 'am', 'shivani', '.', 'i', 'am', 'a', 'engin', 'student', '.']\n"
     ]
    }
   ],
   "source": [
    "print(stemmed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d47db66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function for stemmming\n",
    "def stemming(text):\n",
    "    word_tokens= nltk.word_tokenize(text)\n",
    "    stemmed_word=  [snowball_stemmer.stem(word) for word in word_tokens]\n",
    "    return stemmed_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ce6698d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.32.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input: 'Playing'\n",
    "#Output: \"Play\"\n",
    "#Input: 'Engineering'\n",
    "#Output: \"Engin\"\n",
    "\n",
    "demo4= gr.Interface(fn=stemming, inputs=\"text\", outputs=\"text\")\n",
    "demo4.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e226bc",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b839bfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shivanidangal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "515933cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/shivanidangal/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd0dc914",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens= nltk.word_tokenize(text)\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "lemmatizer_word= [lemmatizer.lemmatize(word) for word in word_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdd84f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n"
     ]
    }
   ],
   "source": [
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac8e7c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'I', 'am', 'Shivani', '.', 'I', 'am', 'a', 'Engineering', 'student', '.']\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97108625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    words= nltk.word_tokenize(text)\n",
    "    lemmatized_word= [lemmatizer.lemmatize(word) for word in words]\n",
    "    return lemmatized_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23fc4baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.32.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input: 'Engineering'\n",
    "#output: 'Engineering'\n",
    "\n",
    "demo5= gr.Interface(fn=lemmatization, inputs=\"text\", outputs=\"text\")\n",
    "demo5.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d2d1dd",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5d90bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shivanidangal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d3d0567",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words= stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a748d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['listening', 'exhausting']\n"
     ]
    }
   ],
   "source": [
    "example= \"can listening be exhausting\"\n",
    "word_tokens = word_tokenize(example)\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "filtered_sentence = []\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3530249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_removal(ex):\n",
    "    word_tokens = word_tokenize(ex)\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    filtered_sentence = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f96e14e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.32.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input: 'In a world where everyone is trying to be someone, it's important to stay true to yourself.'\n",
    "#Output: ['In', 'world', 'everyone', 'trying', 'someone', ',', \"'s\", 'important', 'stay', 'true'](stopwords are removed)\n",
    "\n",
    "demo6= gr.Interface(fn=stopwords_removal, inputs=\"text\", outputs=\"text\")\n",
    "demo6.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3265d3f5",
   "metadata": {},
   "source": [
    "# POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9da92e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/shivanidangal/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14fe4b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= \"They are having their lunch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36988682",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_token= nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "001e66eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('They', 'PRP'), ('are', 'VBP'), ('having', 'VBG'), ('their', 'PRP$'), ('lunch', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "pos_tag= nltk.pos_tag(word_token)\n",
    "print(pos_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa73a03",
   "metadata": {},
   "source": [
    "# TF IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf181ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d0= \"good morning\"\n",
    "d1=\"do daily exercise in the morning\"\n",
    "d3=\"exercise is good for health\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99e0592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "series=[d0,d1,d3]\n",
    "tfidf= TfidfVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d2f834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result= tfidf.fit_transform(series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73a43e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word indexing\n",
      "{'good': 4, 'morning': 8, 'do': 1, 'daily': 0, 'exercise': 2, 'in': 6, 'the': 9, 'is': 7, 'for': 3, 'health': 5}\n"
     ]
    }
   ],
   "source": [
    "print(\"word indexing\")\n",
    "print(tfidf.vocabulary_)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

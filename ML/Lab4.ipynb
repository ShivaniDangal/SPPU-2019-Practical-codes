{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d1opMaPUzRT"
   },
   "source": [
    "Implement Gradient Descent Algorithm to find the local minima of a\n",
    "function.\n",
    "<br>\n",
    "For example, find the local minima of the function y=(x+3)**2 starting from the point x=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nqBt_qVDUZ-6"
   },
   "outputs": [],
   "source": [
    "def cost_function(x):\n",
    "    # ithe given function yenar\n",
    "    return (x + 3) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YDztOHq-Uerk"
   },
   "outputs": [],
   "source": [
    "def gradient(x):\n",
    "    # ithe derivate of given function yenar\n",
    "    return 2 * (x + 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BwGjaBDsUibJ"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "initial_x = 2.0\n",
    "num_iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dWpE1up8UnHY",
    "outputId": "8c60c89c-c667-4e33-e2ff-31ba3136daf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: x = 1.0, Cost = 16.0\n",
      "Iteration 2: x = 0.19999999999999996, Cost = 10.240000000000002\n",
      "Iteration 3: x = -0.44000000000000017, Cost = 6.553599999999998\n",
      "Iteration 4: x = -0.9520000000000001, Cost = 4.194304\n",
      "Iteration 5: x = -1.3616000000000001, Cost = 2.6843545599999996\n",
      "Iteration 6: x = -1.6892800000000001, Cost = 1.7179869183999996\n",
      "Iteration 7: x = -1.951424, Cost = 1.099511627776\n",
      "Iteration 8: x = -2.1611392, Cost = 0.7036874417766399\n",
      "Iteration 9: x = -2.32891136, Cost = 0.4503599627370493\n",
      "Iteration 10: x = -2.463129088, Cost = 0.28823037615171165\n",
      "Iteration 11: x = -2.5705032704, Cost = 0.1844674407370954\n",
      "Iteration 12: x = -2.6564026163200003, Cost = 0.11805916207174093\n",
      "Iteration 13: x = -2.725122093056, Cost = 0.07555786372591429\n",
      "Iteration 14: x = -2.7800976744448, Cost = 0.04835703278458515\n",
      "Iteration 15: x = -2.82407813955584, Cost = 0.030948500982134555\n",
      "Iteration 16: x = -2.8592625116446717, Cost = 0.019807040628566166\n",
      "Iteration 17: x = -2.8874100093157375, Cost = 0.012676506002282305\n",
      "Iteration 18: x = -2.90992800745259, Cost = 0.008112963841460692\n",
      "Iteration 19: x = -2.927942405962072, Cost = 0.005192296858534868\n",
      "Iteration 20: x = -2.9423539247696575, Cost = 0.0033230699894623056\n",
      "Iteration 21: x = -2.953883139815726, Cost = 0.002126764793255884\n",
      "Iteration 22: x = -2.9631065118525806, Cost = 0.0013611294676837786\n",
      "Iteration 23: x = -2.9704852094820646, Cost = 0.0008711228593176078\n",
      "Iteration 24: x = -2.9763881675856516, Cost = 0.0005575186299632732\n",
      "Iteration 25: x = -2.981110534068521, Cost = 0.00035681192317650156\n",
      "Iteration 26: x = -2.984888427254817, Cost = 0.00022835963083295564\n",
      "Iteration 27: x = -2.9879107418038537, Cost = 0.00014615016373308945\n",
      "Iteration 28: x = -2.990328593443083, Cost = 9.353610478917726e-05\n",
      "Iteration 29: x = -2.9922628747544664, Cost = 5.986310706507345e-05\n",
      "Iteration 30: x = -2.993810299803573, Cost = 3.83123885216492e-05\n",
      "Iteration 31: x = -2.995048239842858, Cost = 2.451992865385725e-05\n",
      "Iteration 32: x = -2.9960385918742864, Cost = 1.5692754338469342e-05\n",
      "Iteration 33: x = -2.9968308734994293, Cost = 1.0043362776619255e-05\n",
      "Iteration 34: x = -2.9974646987995435, Cost = 6.427752177036323e-06\n",
      "Iteration 35: x = -2.997971759039635, Cost = 4.113761393302886e-06\n",
      "Iteration 36: x = -2.998377407231708, Cost = 2.6328072917135587e-06\n",
      "Iteration 37: x = -2.998701925785366, Cost = 1.6849966666971388e-06\n",
      "Iteration 38: x = -2.998961540628293, Cost = 1.0783978666865378e-06\n",
      "Iteration 39: x = -2.9991692325026342, Cost = 6.901746346793842e-07\n",
      "Iteration 40: x = -2.9993353860021075, Cost = 4.417117661946878e-07\n",
      "Iteration 41: x = -2.999468308801686, Cost = 2.826955303647891e-07\n",
      "Iteration 42: x = -2.9995746470413485, Cost = 1.8092513943361614e-07\n",
      "Iteration 43: x = -2.9996597176330786, Cost = 1.1579208923763523e-07\n",
      "Iteration 44: x = -2.999727774106463, Cost = 7.410693711203819e-08\n",
      "Iteration 45: x = -2.99978221928517, Cost = 4.7428439751781807e-08\n",
      "Iteration 46: x = -2.9998257754281363, Cost = 3.035420144107846e-08\n",
      "Iteration 47: x = -2.999860620342509, Cost = 1.9426688922339734e-08\n",
      "Iteration 48: x = -2.999888496274007, Cost = 1.243308091029743e-08\n",
      "Iteration 49: x = -2.9999107970192056, Cost = 7.9571717826062e-09\n",
      "Iteration 50: x = -2.9999286376153647, Cost = 5.092589940842615e-09\n",
      "Iteration 51: x = -2.9999429100922916, Cost = 3.259257562149415e-09\n",
      "Iteration 52: x = -2.999954328073833, Cost = 2.0859248397837384e-09\n",
      "Iteration 53: x = -2.9999634624590668, Cost = 1.3349918974486118e-09\n",
      "Iteration 54: x = -2.9999707699672533, Cost = 8.543948143723039e-10\n",
      "Iteration 55: x = -2.999976615973803, Cost = 5.468126811899669e-10\n",
      "Iteration 56: x = -2.9999812927790424, Cost = 3.499601159582557e-10\n",
      "Iteration 57: x = -2.9999850342232337, Cost = 2.2397447421860056e-10\n",
      "Iteration 58: x = -2.999988027378587, Cost = 1.433436634977776e-10\n",
      "Iteration 59: x = -2.9999904219028695, Cost = 9.173994464198049e-11\n",
      "Iteration 60: x = -2.9999923375222957, Cost = 5.871356456950638e-11\n",
      "Iteration 61: x = -2.9999938700178364, Cost = 3.757668132666189e-11\n",
      "Iteration 62: x = -2.999995096014269, Cost = 2.4049076048192486e-11\n",
      "Iteration 63: x = -2.9999960768114153, Cost = 1.5391408670843192e-11\n",
      "Iteration 64: x = -2.9999968614491324, Cost = 9.850501548782124e-12\n",
      "Iteration 65: x = -2.999997489159306, Cost = 6.3043209907745444e-12\n",
      "Iteration 66: x = -2.9999979913274446, Cost = 4.034765434809332e-12\n",
      "Iteration 67: x = -2.9999983930619556, Cost = 2.5822498785634223e-12\n",
      "Iteration 68: x = -2.9999987144495646, Cost = 1.6526399220522305e-12\n",
      "Iteration 69: x = -2.9999989715596516, Cost = 1.0576895502961154e-12\n",
      "Iteration 70: x = -2.9999991772477212, Cost = 6.769213121895138e-13\n",
      "Iteration 71: x = -2.999999341798177, Cost = 4.3322963956744853e-13\n",
      "Iteration 72: x = -2.9999994734385416, Cost = 2.7726696951023927e-13\n",
      "Iteration 73: x = -2.9999995787508333, Cost = 1.7745086041172427e-13\n",
      "Iteration 74: x = -2.9999996630006667, Cost = 1.1356855066350352e-13\n",
      "Iteration 75: x = -2.9999997304005332, Cost = 7.268387247253274e-14\n",
      "Iteration 76: x = -2.9999997843204267, Cost = 4.651767834410857e-14\n",
      "Iteration 77: x = -2.9999998274563415, Cost = 2.977131407892966e-14\n",
      "Iteration 78: x = -2.9999998619650734, Cost = 1.9053640961475125e-14\n",
      "Iteration 79: x = -2.9999998895720585, Cost = 1.2194330254575965e-14\n",
      "Iteration 80: x = -2.999999911657647, Cost = 7.80437133154311e-15\n",
      "Iteration 81: x = -2.9999999293261177, Cost = 4.994797639633387e-15\n",
      "Iteration 82: x = -2.999999943460894, Cost = 3.1966704893653676e-15\n",
      "Iteration 83: x = -2.9999999547687155, Cost = 2.045869097124455e-15\n",
      "Iteration 84: x = -2.9999999638149726, Cost = 1.309356209304147e-15\n",
      "Iteration 85: x = -2.9999999710519782, Cost = 8.379879636702507e-16\n",
      "Iteration 86: x = -2.9999999768415826, Cost = 5.363122967489605e-16\n",
      "Iteration 87: x = -2.999999981473266, Cost = 3.432398699193347e-16\n",
      "Iteration 88: x = -2.9999999851786128, Cost = 2.1967351938118145e-16\n",
      "Iteration 89: x = -2.99999998814289, Cost = 1.4059105661644777e-16\n",
      "Iteration 90: x = -2.999999990514312, Cost = 8.997827286453327e-17\n",
      "Iteration 91: x = -2.9999999924114498, Cost = 5.758609463330129e-17\n",
      "Iteration 92: x = -2.9999999939291597, Cost = 3.685510164371068e-17\n",
      "Iteration 93: x = -2.9999999951433276, Cost = 2.358726677741145e-17\n",
      "Iteration 94: x = -2.999999996114662, Cost = 1.5095850047368678e-17\n",
      "Iteration 95: x = -2.99999999689173, Cost = 9.661342926036557e-18\n",
      "Iteration 96: x = -2.9999999975133838, Cost = 6.18326035608692e-18\n",
      "Iteration 97: x = -2.999999998010707, Cost = 3.957287334634505e-18\n",
      "Iteration 98: x = -2.9999999984085655, Cost = 2.532663894166083e-18\n",
      "Iteration 99: x = -2.999999998726852, Cost = 1.6209053445792253e-18\n",
      "Iteration 100: x = -2.999999998981482, Cost = 1.0373792396055266e-18\n",
      "Optimal x: -2.999999998981482\n"
     ]
    }
   ],
   "source": [
    "x = initial_x\n",
    "for i in range(num_iterations):\n",
    "    gradient_value = gradient(x)\n",
    "    x = x - learning_rate * gradient_value\n",
    "\n",
    "    print(f'Iteration {i+1}: x = {x}, Cost = {cost_function(x)}')\n",
    "\n",
    "print(f'Optimal x: {x}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
